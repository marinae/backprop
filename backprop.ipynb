{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy import misc\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def constructFilenames(data_dir):\n",
    "    \"\"\"\n",
    "    Returns generated filenames for every English letter.\n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    for letter_id in xrange(26):\n",
    "        filenames_of_letter = []\n",
    "        filenames_of_letter.append(data_dir + 'class-' + str(letter_id) + '.bmp')\n",
    "        for f in glob.glob(data_dir + 'mutant-' + str(letter_id) + '-*-*.bmp'):\n",
    "            filenames_of_letter.append(f)\n",
    "        filenames.append(filenames_of_letter)\n",
    "    return filenames\n",
    "\n",
    "def loadData(filenames):\n",
    "    \"\"\"\n",
    "    Returns images (as arrays of greyscale values) and corresponding labels.\n",
    "    \"\"\"\n",
    "    n_letters = len(filenames)\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    for i, letter_files in enumerate(filenames):\n",
    "        images_of_letter = []\n",
    "        label = np.zeros(n_letters)\n",
    "        label[i] = 1\n",
    "        for f in letter_files:\n",
    "            image = misc.imread(f, flatten=True)\n",
    "            images_of_letter.append([pixel / 255.0 for pixel in image.flatten()])\n",
    "        all_images.append(np.asarray(images_of_letter))\n",
    "        all_labels.append([label] * len(letter_files))\n",
    "    return np.asarray(all_images), np.asarray(all_labels)\n",
    "\n",
    "filenames = constructFilenames('../big_alphabet_29x29/')\n",
    "X, Y = loadData(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ThreeFolds(X, Y, train_size=None, test_size=None, cv_size=None):\n",
    "    \"\"\"\n",
    "    Divide X and Y into train, test and validation sets.\n",
    "    \"\"\"\n",
    "    if train_size and test_size:\n",
    "        cv_size = 1 - train_size - test_size\n",
    "    elif train_size and cv_size:\n",
    "        test_size = 1 - train_size - cv_size\n",
    "    elif test_size and cv_size:\n",
    "        train_size = 1 - test_size - cv_size\n",
    "    else:\n",
    "        raise ValueError('Not enough parameters for function')\n",
    "\n",
    "    all_samples = np.arange(X.shape[1])\n",
    "    N = len(all_samples)\n",
    "    train = np.random.choice(all_samples, int(train_size * N), replace=False)\n",
    "    all_samples = np.setdiff1d(all_samples, train)\n",
    "    test = np.random.choice(all_samples, int(test_size * N), replace=False)\n",
    "    cv = np.setdiff1d(all_samples, test)\n",
    "\n",
    "    X_train, X_test, X_cv = X[:, train].reshape((-1, X.shape[2])), \\\n",
    "                            X[:, test].reshape((-1, X.shape[2])), \\\n",
    "                            X[:, cv].reshape((-1, X.shape[2]))\n",
    "    Y_train, Y_test, Y_cv = Y[:, train].reshape((-1, Y.shape[2])), \\\n",
    "                            Y[:, test].reshape((-1, Y.shape[2])), \\\n",
    "                            Y[:, cv].reshape((-1, Y.shape[2]))\n",
    "    return [X_train, Y_train], [X_test, Y_test], [X_cv, Y_cv]\n",
    "\n",
    "train, test, cv = ThreeFolds(X, Y, train_size=0.6, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Activation functions #########################\n",
    "\n",
    "def sigmoid(z, a=1.0):\n",
    "    \"\"\"\n",
    "    :param z: input value\n",
    "    :return:  sigmoid function\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-a * z))\n",
    "\n",
    "def d_sigmoid(z, a=1.0):\n",
    "    \"\"\"\n",
    "    :param z: input value\n",
    "    :return:  derivative of sigmoid\n",
    "    \"\"\"\n",
    "    s = sigmoid(z, a)\n",
    "    return a * s * (1 - s)\n",
    "\n",
    "##### Cost functions ###############################\n",
    "\n",
    "def xeuclidian(t, y):\n",
    "    \"\"\"\n",
    "    :param t: true values\n",
    "    :param y: predicted values\n",
    "    :return:  half of squared Euclidian distance\n",
    "    \"\"\"\n",
    "    return np.sum((t - y) ** 2, axis=1) / 2.0\n",
    "\n",
    "def d_xeuclidian(t, y):\n",
    "    \"\"\"\n",
    "    :param t: true values\n",
    "    :param y: predicted values\n",
    "    :return:  derivative of xeuclidian\n",
    "    \"\"\"\n",
    "    return y - t\n",
    "\n",
    "@np.vectorize\n",
    "def loglikelihood_elements(t, y):\n",
    "    return(0 if t == 0 or y == 1 else (t * np.log(y) if y != 0 else t * np.log(np.finfo(float).eps))) + \\\n",
    "          (0 if t == 1 or y == 0 else ((1 - t) * np.log(1 - y) if y != 1 else (1 - t) * np.log(np.finfo(float).eps)))\n",
    "\n",
    "def loglikelihood(t, y):\n",
    "    \"\"\"\n",
    "    :param t: true values\n",
    "    :param y: predicted values\n",
    "    :return:  log of Bernoulli likelihood\n",
    "    \"\"\"\n",
    "    return -np.sum(loglikelihood_elements(t, y), axis=1)\n",
    "    \n",
    "@np.vectorize\n",
    "def d_loglikelihood(t, y):\n",
    "    \"\"\"\n",
    "    :param t: true values\n",
    "    :param y: predicted values\n",
    "    :return:  derivative of loglikelihood\n",
    "    \"\"\"\n",
    "    return -(t / y if y != 0 else t / np.finfo(float).eps) + \\\n",
    "           ((1 - t) / (1 - y) if y != 1 else (1 - t) / np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron with backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 4.41995\n",
      "Test error:  5.22004\n"
     ]
    }
   ],
   "source": [
    "class MultilayerPerceptron:\n",
    "    \"\"\"\n",
    "    Multilayer Perceptron (MLP) with backward propagation training algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 structure,\n",
    "                 activation_functions=None,\n",
    "                 d_activation_functions=None,\n",
    "                 cost_function=None,\n",
    "                 d_cost_function=None):\n",
    "        \"\"\"\n",
    "        :param structure:              tuple of neurons count in each layer\n",
    "        :param activation_functions:   list of activation functions, sigmoids by default\n",
    "        :param d_activation_functions: list of derivatives of activation functions\n",
    "        :param cost_function:          cost function, xeuclidian by default\n",
    "        :param d_cost_function:        derivative of cost function\n",
    "        \"\"\"\n",
    "        if activation_functions is not None and d_activation_functions is None:\n",
    "            raise ValueError('Derivatives of activation functions not specified')\n",
    "        if activation_functions is None and d_activation_functions is not None:\n",
    "            raise ValueError('Activation functions not specified')\n",
    "        if activation_functions is not None and len(activation_functions) != len(d_activation_functions):\n",
    "            raise ValueError('Different number of activation functions and their derivatives')\n",
    "            \n",
    "        if cost_function is not None and d_cost_function is None:\n",
    "            raise ValueError('Derivative of cost function not specified')\n",
    "        if cost_function is None and d_cost_function is not None:\n",
    "            raise ValueError('Cost function not specified')\n",
    "            \n",
    "        if activation_functions is not None and len(activation_functions) != len(structure):\n",
    "            raise ValueError('Size of activation_functions conflicts with structure')\n",
    "            \n",
    "        self.structure = structure\n",
    "        if activation_functions is not None:\n",
    "            self.activation = activation_functions\n",
    "            self.d_activation = d_activation_functions\n",
    "        else:\n",
    "            self.activation = map(lambda x: lambda z: sigmoid(z), xrange(len(structure)))\n",
    "            self.d_activation = map(lambda x: lambda z: d_sigmoid(z), xrange(len(structure)))\n",
    "        if cost_function is not None:\n",
    "            self.cost = cost_function\n",
    "            self.d_cost = d_cost_function\n",
    "        else:\n",
    "            self.cost = xeuclidian\n",
    "            self.d_cost = d_xeuclidian\n",
    "            \n",
    "    def init_weights(self, input_dim, f_init):\n",
    "        \"\"\"\n",
    "        :param input_dim: dimension of input sample\n",
    "        :param f_init:    function that returns initial weights for layer with size n\n",
    "        :return:          list of weight matrices\n",
    "        \"\"\"\n",
    "        W = []\n",
    "        for i, layer in enumerate(self.structure):\n",
    "            inputs = 1 + (input_dim if i == 0 else self.structure[i - 1])\n",
    "            W.append(f_init(inputs * layer).reshape(inputs, layer))\n",
    "        return W\n",
    "    \n",
    "    def forward_pass(self, X, cache=False):\n",
    "        \"\"\"\n",
    "        :param X:     input samples\n",
    "        :param cache: if True then intermediate results will be cached\n",
    "        :return:      MLP prediction\n",
    "        \"\"\"\n",
    "        cur_X = X\n",
    "        self.z = []\n",
    "        self.f_z = []\n",
    "        for i, matrix in enumerate(self.W):\n",
    "            \n",
    "            # Add bias to input data\n",
    "            tmp = np.c_[np.ones(cur_X.shape[0]), cur_X]\n",
    "\n",
    "            # Compute next layer\n",
    "            cur_z = np.dot(tmp, matrix)\n",
    "            cur_X = self.activation[i](cur_z)\n",
    "            \n",
    "            # Remember intermediate result\n",
    "            if cache:\n",
    "                self.z.append(cur_z)\n",
    "                self.f_z.append(cur_X)\n",
    "            \n",
    "        return cur_X\n",
    "    \n",
    "    def backward_pass(self, X, Y):\n",
    "        \"\"\"\n",
    "        :param X: input data\n",
    "        :param Y: output data\n",
    "        :return:  gradient for weights in each layer\n",
    "        \"\"\"\n",
    "        dE_dw = [None] * len(self.W)\n",
    "        dE_dz_next = None\n",
    "        \n",
    "        # Iterate from last layer to first one\n",
    "        for i in reversed(xrange(len(self.W))):\n",
    "            dE_dz = None\n",
    "            \n",
    "            # Output layer\n",
    "            if dE_dz_next is None:\n",
    "                dE_dz = self.d_cost(Y, self.f_z[i]) * self.d_activation[i](self.z[i])\n",
    "                \n",
    "            # Hidden layer\n",
    "            else:\n",
    "                dE_dz = np.dot(dE_dz_next, self.W[i + 1][1:].T) * self.d_activation[i](self.z[i])\n",
    "                \n",
    "            dE_dz_next = dE_dz\n",
    "            \n",
    "            # Add bias to layer input data\n",
    "            layer_input = X if i == 0 else self.f_z[i - 1]\n",
    "            layer_input = np.c_[np.ones(layer_input.shape[0]), layer_input]\n",
    "\n",
    "            # Compute gradient\n",
    "            dE_dw[i] = np.dot(layer_input.T, dE_dz) / X.shape[0]\n",
    "            \n",
    "        return dE_dw\n",
    "        \n",
    "    def fit(self,\n",
    "            train,\n",
    "            cv=[None, None],\n",
    "            f_init=(lambda n: np.random.normal(0, 0.1, n)),\n",
    "            max_iter=5000,\n",
    "            learning_rate=0.1,\n",
    "            eps=0.05,\n",
    "            verbose=False):\n",
    "        \"\"\"\n",
    "        :param train:         train set (samples and labels)\n",
    "        :param cv:            validation set (samples and labels), optional\n",
    "        :param f_init:        function that returns initial weights for layer with size n\n",
    "        :param max_iter:      maximum number of iterations\n",
    "        :param learning_rate: learning rate in MLP\n",
    "        :return:              object\n",
    "        \"\"\"\n",
    "        X_train, Y_train = train\n",
    "        X_cv, Y_cv = cv\n",
    "        self.train_loss = []\n",
    "        self.cv_loss = []\n",
    "        \n",
    "        # Initialize weight matrices\n",
    "        self.W = self.init_weights(X_train.shape[1], f_init)  \n",
    "        \n",
    "        # Main loop\n",
    "        for n_iter in xrange(max_iter):\n",
    "            \n",
    "            # Forward pass\n",
    "            cur_X = self.forward_pass(X_train, cache=True)\n",
    "            \n",
    "            # Backward pass\n",
    "            dE_dw = self.backward_pass(X_train, Y_train)\n",
    "            \n",
    "            # Update weights\n",
    "            for i in xrange(len(self.W)):\n",
    "                self.W[i] = self.W[i] - learning_rate * dE_dw[i]\n",
    "            \n",
    "            # Compute prediction error on train set\n",
    "            self.train_loss.append(np.sum(self.cost(self.predict(X_train), Y_train)) / X_train.shape[0])\n",
    "            \n",
    "            # Compute prediction error on validation set\n",
    "            if X_cv is not None:\n",
    "                self.cv_loss.append(np.sum(self.cost(self.predict(X_cv), Y_cv)) / X_cv.shape[0])\n",
    "                \n",
    "                # Check for early stop condition\n",
    "                if (1 - eps) * self.cv_loss[-1] > np.min(self.cv_loss):\n",
    "                    break\n",
    "                    \n",
    "            if verbose:\n",
    "                print 'Iter %d:\\ttrain loss = %0.5f' % (n_iter, self.train_loss[-1]),\n",
    "                if X_cv is not None:\n",
    "                    print ', CV loss = %0.5f' % self.cv_loss[-1]\n",
    "                else:\n",
    "                    print\n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: input samples\n",
    "        :return:  MLP prediction\n",
    "        \"\"\"\n",
    "        return self.forward_pass(X)\n",
    "        \n",
    "mlp = MultilayerPerceptron(structure=(30, 26), cost_function=loglikelihood, d_cost_function=d_loglikelihood)\n",
    "mlp.fit(train, cv)\n",
    "\n",
    "X_test, Y_test = test\n",
    "Y_pred = mlp.predict(X_test)\n",
    "print 'Train error: %0.5f' % mlp.train_loss[-1]\n",
    "print 'Test error:  %0.5f' % (np.sum(loglikelihood(Y_pred, Y_test)) / X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAH4CAYAAABAATQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106a08e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(8, 8))\n",
    "\n",
    "N = len(mlp.train_loss)\n",
    "t = np.linspace(1, N, N, endpoint=True)\n",
    "\n",
    "train_loss, = pl.plot(t, mlp.train_loss, color='blue')\n",
    "cv_loss, = pl.plot(t, mlp.cv_loss, color='red')\n",
    "pl.title('Error of MLP prediction')\n",
    "pl.legend([train_loss, cv_loss], ['Train', 'CV'])\n",
    "pl.xlabel('Iterations')\n",
    "pl.ylabel('Error')\n",
    "pl.xlim(1, N)\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% correct labels\n"
     ]
    }
   ],
   "source": [
    "#print 'True\\tPredicted label'\n",
    "count = 0\n",
    "for i, y in enumerate(Y_test):\n",
    "    y_true = np.argmax(y)\n",
    "    y_pred = np.argmax(Y_pred[i])\n",
    "    if y_true == y_pred:\n",
    "        count += 1\n",
    "    #print '%d\\t%d' % (y_true, y_pred)\n",
    "print '%0.1f%% correct labels' % (float(count) / len(Y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
