{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import sklearn.utils as util\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate impurity in node\n",
    "def node_impurity(y):\n",
    "    \n",
    "    mean = np.mean(y)\n",
    "    delta = np.subtract(y, mean)\n",
    "    return np.dot(delta, delta)\n",
    "\n",
    "# Calculate normalized impurity in node\n",
    "def node_impurity_norm(y):\n",
    "\n",
    "    return node_impurity(y) / float(len(y))\n",
    "\n",
    "# Find impurity after splitting\n",
    "def impurity_after_split(y, i):\n",
    "\n",
    "    l_samples = y[:i]\n",
    "    r_samples = y[i:]\n",
    "    N_l = i\n",
    "    N_r = len(y) - i\n",
    "    \n",
    "    return N_l * node_impurity_norm(l_samples) + N_r * node_impurity_norm(r_samples)\n",
    "\n",
    "# Find best split for node\n",
    "def find_split(node):\n",
    "    \n",
    "    new_impurity = +inf\n",
    "    min_impurity = +inf\n",
    "    feature = None\n",
    "    threshold = None\n",
    "    l_rows = None\n",
    "    r_rows = None\n",
    "    \n",
    "    for j in xrange(node.X.shape[1]):\n",
    "        x_column = node.X[:, j]\n",
    "        rows = np.argsort(x_column)\n",
    "        x_sorted = x_column[rows]\n",
    "        y_sorted = node.Y[rows]\n",
    "        \n",
    "        for i in xrange(1, len(x_sorted)):   \n",
    "            \n",
    "            if x_sorted[i] == x_sorted[i - 1]:\n",
    "                continue\n",
    "                \n",
    "            new_impurity = impurity_after_split(y_sorted, i)\n",
    "            \n",
    "            if new_impurity < min_impurity:\n",
    "                min_impurity = new_impurity\n",
    "                feature = j\n",
    "                threshold = (x_sorted[i] + x_sorted[i - 1]) / 2.0\n",
    "                l_rows = rows[:i]\n",
    "                r_rows = rows[i:]\n",
    "\n",
    "    return feature, threshold, l_rows, r_rows\n",
    "    \n",
    "# Define a tree node\n",
    "class CNode:\n",
    "    \n",
    "    def __init__(self, X, Y, feature=None, threshold=None, depth=0, parent=None):\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.depth = depth\n",
    "        self.parent = parent\n",
    "        \n",
    "        self.impurity = node_impurity_norm(Y)\n",
    "        self.reduction = None\n",
    "        self.mean = None\n",
    "        \n",
    "    def split(self):\n",
    "\n",
    "        feature, threshold, l_rows, r_rows = find_split(self)\n",
    "        \n",
    "        if feature is not None:\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.reduction = node_impurity(self.Y) - node_impurity(self.Y[l_rows]) - node_impurity(self.Y[r_rows])\n",
    "            left_node = CNode(self.X[l_rows], self.Y[l_rows], depth=self.depth + 1)\n",
    "            right_node = CNode(self.X[r_rows], self.Y[r_rows], depth=self.depth + 1)\n",
    "            \n",
    "        else:\n",
    "            left_node = None\n",
    "            right_node = None\n",
    "        \n",
    "        return left_node, right_node\n",
    "        \n",
    "# Define a decision tree\n",
    "class CTree:\n",
    "    \n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        \n",
    "        self.nodes = []\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        self.nodes = np.array([CNode(X, Y)])\n",
    "        self.feature_importances = np.zeros(X.shape[1])\n",
    "        todo = np.array([0])\n",
    "        \n",
    "        while todo.size > 0:\n",
    "            index = todo[0]\n",
    "            todo = todo[1:]\n",
    "            \n",
    "            if self.nodes[index].depth < self.max_depth and len(self.nodes[index].X) > self.min_samples_split:\n",
    "                \n",
    "                left, right = self.nodes[index].split()\n",
    "\n",
    "                if left is not None:\n",
    "                    N = len(self.nodes)\n",
    "                    self.nodes[index].left = N\n",
    "                    self.nodes[index].right = N + 1\n",
    "                    left.parent = index\n",
    "                    right.parent = index\n",
    "                    self.nodes = np.append(self.nodes, [left, right])\n",
    "                    feature = self.nodes[index].feature\n",
    "                    self.feature_importances[feature] += self.nodes[index].reduction\n",
    "                    todo = np.append(todo, [N, N + 1])\n",
    "                    continue\n",
    "                    \n",
    "            self.nodes[index].mean = np.mean(self.nodes[index].Y)\n",
    "            self.nodes[index].X = None\n",
    "            self.nodes[index].Y = None\n",
    "            \n",
    "        self.feature_importances = self.feature_importances / float(np.sum(self.feature_importances))\n",
    "                \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        answer = np.zeros(X.shape[0])\n",
    "        \n",
    "        if len(self.nodes) == 0:\n",
    "            return answer\n",
    "        \n",
    "        for i in xrange(X.shape[0]):\n",
    "            index = 0\n",
    "            \n",
    "            while self.nodes[index].mean is None:\n",
    "                feature = self.nodes[index].feature\n",
    "                threshold = self.nodes[index].threshold\n",
    "                if X[i, feature] <= threshold:\n",
    "                    index = self.nodes[index].left\n",
    "                else:\n",
    "                    index = self.nodes[index].right\n",
    "            answer[i] = self.nodes[index].mean\n",
    "            \n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling\n",
    "def sampleData(X, Y, sample):\n",
    "    \n",
    "    x, y = util.shuffle(X, Y)\n",
    "    offset = int(x.shape[0] * sample)\n",
    "    \n",
    "    return x[:offset], y[:offset]\n",
    "\n",
    "# Define regressor class\n",
    "class MyRegressor:\n",
    "    \n",
    "    def __init__(self, n_estimators=100, max_depth=3, min_samples_split=2, learning_rate=0.1, subsample=0.5, verbose=0):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = [None] * n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.learning_rate = learning_rate\n",
    "        self.subsample = subsample\n",
    "        self.verbose = verbose\n",
    "        self.h = [0] * n_estimators\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        if self.verbose == 1:\n",
    "            print \"Iter\\tTrain Loss\"\n",
    "        \n",
    "        self.init_value = np.mean(Y)\n",
    "        initial = np.empty(X.shape[0])\n",
    "        initial.fill(self.init_value)\n",
    "        self.loss = np.zeros(self.n_estimators)\n",
    "        self.feature_importances = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in xrange(self.n_estimators):\n",
    "\n",
    "            if i == 0:\n",
    "                prev = initial\n",
    "            else:\n",
    "                prev = self.h[i - 1]\n",
    "                \n",
    "            G = Y - prev\n",
    "            x, g = sampleData(X, G, self.subsample)\n",
    "            \n",
    "            self.estimators[i] = CTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            self.estimators[i].fit(x, g)\n",
    "            self.feature_importances += self.learning_rate * self.estimators[i].feature_importances\n",
    "            self.h[i] = prev + self.learning_rate * self.estimators[i].predict(X)\n",
    "            self.loss[i] = mean_squared_error(self.h[i], Y)\n",
    "               \n",
    "            if self.verbose == 1:\n",
    "                if i <= 10 or i % 10 == 0:\n",
    "                    print \"%d\\t%0.4f\" % (i, self.loss[i])\n",
    "                    \n",
    "        self.feature_importances = self.feature_importances / float(np.sum(self.feature_importances))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X, Y=None):\n",
    "\n",
    "        answer = np.empty(X.shape[0])\n",
    "        answer.fill(self.init_value)\n",
    "        \n",
    "        if Y is not None:\n",
    "            self.test_loss = np.zeros(self.n_estimators)\n",
    "        \n",
    "        for i in xrange(self.n_estimators):\n",
    "            answer += self.learning_rate * self.estimators[i].predict(X)\n",
    "            \n",
    "            if Y is not None:\n",
    "                self.test_loss[i] = mean_squared_error(answer, Y)\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load spam dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam train:\t7093 rows x 102 features\n",
      "Spam test:\t10056 rows x 102 features\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"datasets/spam-train.txt\", delim_whitespace=True, header=None)\n",
    "test_df = pd.read_csv(\"datasets/spam-test.txt\", delim_whitespace=True, header=None)\n",
    "\n",
    "# Create matrices from dataframes\n",
    "Y_train = train_df[0].as_matrix()\n",
    "Y_test = test_df[0].as_matrix()\n",
    "\n",
    "X_train = train_df.drop(0, axis=1).as_matrix()\n",
    "X_test = test_df.drop(0, axis=1).as_matrix()\n",
    "\n",
    "print \"Spam train:\\t%d rows x %d features\" % (X_train.shape[0], X_train.shape[1])\n",
    "print \"Spam test:\\t%d rows x %d features\" % (X_test.shape[0], X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter feature selection (CFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correlation(a, b):\n",
    "    mean_a = np.mean(a)\n",
    "    mean_b = np.mean(b)\n",
    "    \n",
    "    delta_a = np.subtract(a, mean_a)\n",
    "    delta_b = np.subtract(b, mean_b)\n",
    "    \n",
    "    numer = np.sum(delta_a * delta_b)\n",
    "    denom = sqrt(np.dot(delta_a, delta_a)) * sqrt(np.dot(delta_b, delta_b))\n",
    "\n",
    "    return numer / float(denom)\n",
    "\n",
    "def corr_matrix(X):\n",
    "    matrix = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "    for i in xrange(X.shape[1]):\n",
    "        matrix[i, i] = 1\n",
    "        for j in xrange(i + 1, X.shape[1]):\n",
    "            matrix[i, j] = correlation(X[:, i], X[:, j])\n",
    "            matrix[j, i] = matrix[i, j]\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "def filterFS(X, Y):\n",
    "    all_features = np.arange(X.shape[1])\n",
    "    features = []\n",
    "    \n",
    "    cross_corr = corr_matrix(X)\n",
    "    y_corr = np.array([correlation(X_train[:, f], Y_train) for f in all_features])\n",
    "    \n",
    "    numer = 0\n",
    "    denom = 1\n",
    "    \n",
    "    while len(all_features) > 0:\n",
    "        best = all_features[0]\n",
    "        max_cfs = -inf\n",
    "\n",
    "        for f in all_features:\n",
    "\n",
    "            f_cross = np.sum([cross_corr[f, j] for j in features])\n",
    "            cfs = (numer + abs(y_corr[f]) / sqrt(denom + 2 * f_cross))\n",
    "\n",
    "            if cfs > max_cfs:\n",
    "                best = f\n",
    "                max_cfs = cfs\n",
    "\n",
    "        features.append(best)\n",
    "        all_features = np.setdiff1d(all_features, [best], assume_unique=True)\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run regressor on feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48  70  49 101  31  10  56   9   8  51  53  11  14  41  74  52  32  85\n",
      "  71  76   4  99  12  29  83  13   3  89  75  50  80  98  78  73  87  90\n",
      "  15   1   2  19  44  61  16  72  62  35  28  47  77  86 100  92  79  95\n",
      "  46  88  17  91  42  39  96  94  57  43  97  93  18  38   0  81  64  65\n",
      "  30  82  25  66   5  63  58  37  20  59  60  84  68   6  54  33  45  67\n",
      "   7  22  69  34  27  55  36  23  24  21  26  40]\n",
      "Number of features: 1\tTrain loss: 0.1531\tTest loss: 0.1215\n",
      "Number of features: 2\tTrain loss: 0.1154\tTest loss: 0.1347\n",
      "Number of features: 3\tTrain loss: 0.0960\tTest loss: 0.1441\n",
      "Number of features: 4\tTrain loss: 0.0757\tTest loss: 0.1339\n",
      "Number of features: 5\tTrain loss: 0.0717\tTest loss: 0.1278\n",
      "Number of features: 6\tTrain loss: 0.0596\tTest loss: 0.1190\n",
      "Number of features: 7\tTrain loss: 0.0603\tTest loss: 0.1184\n",
      "Number of features: 8\tTrain loss: 0.0569\tTest loss: 0.1151\n",
      "Number of features: 9\tTrain loss: 0.0532\tTest loss: 0.0984\n",
      "Number of features: 10\tTrain loss: 0.0533\tTest loss: 0.1037\n",
      "Number of features: 11\tTrain loss: 0.0505\tTest loss: 0.0993\n",
      "Number of features: 12\tTrain loss: 0.0501\tTest loss: 0.0949\n",
      "Number of features: 13\tTrain loss: 0.0490\tTest loss: 0.0924\n",
      "Number of features: 14\tTrain loss: 0.0475\tTest loss: 0.0980\n",
      "Number of features: 15\tTrain loss: 0.0468\tTest loss: 0.0974\n",
      "Number of features: 16\tTrain loss: 0.0452\tTest loss: 0.0902\n",
      "Number of features: 21\tTrain loss: 0.0403\tTest loss: 0.0662\n",
      "Number of features: 26\tTrain loss: 0.0389\tTest loss: 0.0659\n",
      "Number of features: 31\tTrain loss: 0.0390\tTest loss: 0.0647\n",
      "Number of features: 46\tTrain loss: 0.0380\tTest loss: 0.0661\n",
      "Number of features: 61\tTrain loss: 0.0361\tTest loss: 0.0718\n",
      "Number of features: 76\tTrain loss: 0.0361\tTest loss: 0.0718\n",
      "Number of features: 91\tTrain loss: 0.0358\tTest loss: 0.0712\n",
      "Number of features: 102\tTrain loss: 0.0357\tTest loss: 0.0720\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'subsample': 0.5, 'verbose': 0}\n",
    "indices = filterFS(X_train, Y_train)\n",
    "print indices\n",
    "\n",
    "mse_train = []\n",
    "mse_test = []\n",
    "t = []\n",
    "\n",
    "for n in xrange(X_train.shape[1]):\n",
    "    if (n < 15) or (n < 30 and n % 5 == 0) or (n % 15 == 0) or (n == X_train.shape[1] - 1):\n",
    "        \n",
    "        t.append(n)\n",
    "        cur_indices = indices[:(n + 1)]\n",
    "\n",
    "        reg = MyRegressor(**params)\n",
    "        reg.fit(X_train[:, cur_indices], Y_train)\n",
    "\n",
    "        pred_train = reg.predict(X_train[:, cur_indices])\n",
    "        pred_test = reg.predict(X_test[:, cur_indices])\n",
    "\n",
    "        mse_train.append(mean_squared_error(pred_train, Y_train))\n",
    "        mse_test.append(mean_squared_error(pred_test, Y_test))\n",
    "\n",
    "        i = len(mse_train) - 1\n",
    "        print \"Number of features: %d\\tTrain loss: %0.4f\\tTest loss: %0.4f\" % (n + 1, mse_train[i], mse_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 17\tTrain loss: 0.0449\tTest loss: 0.0928\n",
      "Number of features: 18\tTrain loss: 0.0441\tTest loss: 0.0900\n",
      "Number of features: 19\tTrain loss: 0.0418\tTest loss: 0.0640\n",
      "Number of features: 20\tTrain loss: 0.0413\tTest loss: 0.0690\n"
     ]
    }
   ],
   "source": [
    "for n in xrange(16, 20):\n",
    "    \n",
    "    cur_indices = indices[:(n + 1)]\n",
    "\n",
    "    reg = MyRegressor(**params)\n",
    "    reg.fit(X_train[:, cur_indices], Y_train)\n",
    "\n",
    "    pred_train = reg.predict(X_train[:, cur_indices])\n",
    "    pred_test = reg.predict(X_test[:, cur_indices])\n",
    "\n",
    "    print \"Number of features: %d\\tTrain loss: %0.4f\\tTest loss: %0.4f\" % (n + 1,\n",
    "                                                                           mean_squared_error(pred_train, Y_train),\n",
    "                                                                           mean_squared_error(pred_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [ 48  70  49 101  31  10  56   9   8  51  53  11  14  41  74  52  32  85\n",
      "  71]\n"
     ]
    }
   ],
   "source": [
    "print \"Selected features:\", indices[:19]  # [48, 70, 49, 101, 31, 10, 56, 9, 8, 51, 53, 11, 14, 41, 74, 52, 32, 85, 71]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot train & test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH4CAYAAAC8FB/xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e924d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(8, 8))\n",
    "\n",
    "N = X_train.shape[1]\n",
    "tt = np.add(t, 1)\n",
    "\n",
    "train, = pl.plot(tt, mse_train, color=\"red\", linewidth=1.0, linestyle=\"-\", marker='o')\n",
    "test, = pl.plot(tt, mse_test, color=\"blue\", linewidth=1.0, linestyle=\"-\", marker='o')\n",
    "pl.xlim(1, N)\n",
    "pl.title(\"spam\")\n",
    "pl.legend([train, test], ['train loss', 'test loss'])\n",
    "pl.xlabel(\"Number of features\")\n",
    "pl.ylabel(\"Mean squared error\")\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on sklearn regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on 102 features:\t0.0694823701\n",
      "MSE on 19 features:\t0.0640259041\n"
     ]
    }
   ],
   "source": [
    "model_sk = ensemble.GradientBoostingRegressor(**params)\n",
    "model_sk.fit(X_train, Y_train)\n",
    "mse_sklearn = mean_squared_error(model_sk.predict(X_test), Y_test)\n",
    "print \"MSE on %d features:\\t%0.10f\" % (X_train.shape[1], mse_sklearn)\n",
    "\n",
    "X_train_small = X_train[:, indices[:19]]\n",
    "X_test_small = X_test[:, indices[:19]]\n",
    "\n",
    "model_sk_small = ensemble.GradientBoostingRegressor(**params)\n",
    "model_sk_small.fit(X_train_small, Y_train)\n",
    "mse_sklearn_small = mean_squared_error(model_sk_small.predict(X_test_small), Y_test)\n",
    "print \"MSE on %d features:\\t%0.10f\" % (X_train_small.shape[1], mse_sklearn_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
